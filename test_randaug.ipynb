{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Environment ###\n",
    "\n",
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import random\n",
    "# import export\n",
    "from timm.data.auto_augment import rand_augment_transform\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from timm.data.transforms import RandomResizedCropAndInterpolation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters for Tests ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "\n",
    "BASE_DIR = \"/data\"\n",
    "IMAGE_PATH = os.path.join(\"Metaformer\", \"layerjot\", \"n1_multimodal_data\", \"images\")\n",
    "IMAGE_DIR = os.path.join(BASE_DIR, IMAGE_PATH)\n",
    "\n",
    "CLASS_DIRS = os.listdir(IMAGE_DIR)\n",
    "N_CLASSES = 1\n",
    "N_IMAGES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_and_display(image_file, mag=10, n_layers=2, hparams=None):\n",
    "    config_str = \"rand-m{}-n{}\".format(mag, n_layers)\n",
    "    crop = RandomResizedCropAndInterpolation(size=224, scale=(0.8, 1))\n",
    "    rand_tfm = rand_augment_transform(config_str=config_str, hparams=hparams)\n",
    "\n",
    "    image = Image.open(image_file)\n",
    "    plt.imshow(crop(image))\n",
    "\n",
    "    fig, ax = plt.subplots(2, 4, figsize=(10,5))\n",
    "    for idx, im in enumerate([rand_tfm(crop(image)) for i in range(4)]):\n",
    "        ax[0, idx].imshow(im)\n",
    "    for idx, im in enumerate([rand_tfm(crop(image)) for i in range(4)]):\n",
    "        ax[1, idx].imshow(im)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cidx in range(N_CLASSES):\n",
    "    random.shuffle(CLASS_DIRS)\n",
    "    display_class_dir = CLASS_DIRS[0]\n",
    "    images_path = os.path.join(IMAGE_DIR, display_class_dir)\n",
    "    all_images = os.listdir(images_path)\n",
    "    for imidx in range(N_IMAGES):\n",
    "        random.shuffle(all_images)\n",
    "        image_file = os.path.join(images_path, all_images[0])\n",
    "        print(image_file)\n",
    "        transform_and_display(image_file, mag=5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
